{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT 5\n",
    "Leen Said 2220356194 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=pd.read_csv(\"C:/Users/leens/Downloads/16P.csv\",header=0, encoding='cp1252')\n",
    "df=pd.DataFrame(p)\n",
    "df['Personality'].replace(\"ESTJ\",0 , inplace=True)\n",
    "df['Personality'].replace(\"ENTJ\",1 , inplace=True)\n",
    "df['Personality'].replace(\"ESFJ\",2 , inplace=True)\n",
    "df['Personality'].replace(\"ENFJ\",3 , inplace=True)\n",
    "df['Personality'].replace(\"ISTJ\",4 , inplace=True)\n",
    "df['Personality'].replace(\"ISFJ\",5 , inplace=True)\n",
    "df['Personality'].replace(\"INTJ\",6 , inplace=True)\n",
    "df['Personality'].replace(\"INFJ\",7 , inplace=True)\n",
    "df['Personality'].replace(\"ESTP\",8 , inplace=True)\n",
    "df['Personality'].replace(\"ESFP\",9 , inplace=True)\n",
    "df['Personality'].replace(\"ENTP\",10 , inplace=True)\n",
    "df['Personality'].replace(\"ENFP\",11 , inplace=True)\n",
    "df['Personality'].replace(\"ISTP\",12 , inplace=True)\n",
    "df['Personality'].replace(\"ISFP\",13 , inplace=True)\n",
    "df['Personality'].replace(\"INTP\",14 , inplace=True)\n",
    "df['Personality'].replace(\"INFP\",15 , inplace=True)\n",
    "df=df.drop(['Response Id'], axis=1)\n",
    "\n",
    "clist = list(df.columns)\n",
    "clist_pred, clist_target = clist[:-1], clist[-1]\n",
    "independent_df, dependent_df = df[clist_pred], df[clist_target] \n",
    "independent_array, dependent_array, main = independent_df.to_numpy() , dependent_df.to_numpy(), df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataframe(X_train, X_test):\n",
    "    # Normalize each column in the DataFrame\n",
    "    X_train = (X_train - X_train.min(axis=0)) / (X_train.max(axis=0) - X_train.min(axis=0))\n",
    "    X_test = (X_test - X_test.min(axis=0)) / (X_test.max(axis=0) - X_test.min(axis=0))\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    # Initialize a variable to store the number of correct predictions\n",
    "    correct = 0\n",
    "    \n",
    "    # Iterate over each element in y_true\n",
    "    for i in range(len(y_true)):\n",
    "        # Check if the prediction for the current element is correct\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            # If the prediction is correct, increment the correct variable by 1\n",
    "            correct += 1\n",
    "    # Return the proportion of correct predictions\n",
    "    return correct / len(y_true)\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    # Initialize a dictionary to store the number of true positive for each class label\n",
    "    true_positive = {k: 0 for k in set(y_true)}\n",
    "    # Initialize a dictionary to store the number of false positive for each class label\n",
    "    false_positive = {k: 0 for k in set(y_true)}\n",
    "    # Iterate over the true and predicted class labels\n",
    "    for i in range(len(y_true)):\n",
    "        # If the true and predicted class labels match\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            # Increment the count of true positive for that class label\n",
    "            if y_true[i] not in true_positive:\n",
    "                true_positive[y_true[i]] = 1\n",
    "            else:\n",
    "                true_positive[y_true[i]] += 1\n",
    "        # If the true and predicted class labels do not match\n",
    "        else:\n",
    "            # Increment the count of false positive for that class label\n",
    "            if y_pred[i] not in false_positive:\n",
    "                false_positive[y_pred[i]] = 1\n",
    "            else:\n",
    "                false_positive[y_pred[i]] += 1\n",
    "    # Initialize an empty list to store precision for each class label\n",
    "    precision = []\n",
    "    # Calculate precision for each class label\n",
    "    for label in set(y_true):\n",
    "        if true_positive[label] + false_positive[label] != 0:  # check for division by zero\n",
    "            precision.append(true_positive[label] / (true_positive[label] + false_positive[label]))\n",
    "    # Return the mean precision\n",
    "    return np.mean(precision)\n",
    "\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    # Initialize a dictionary to store the number of true positive for each class label\n",
    "    true_positive = {k: 0 for k in set(y_true)}\n",
    "    # Initialize a dictionary to store the number of false negative for each class label\n",
    "    false_negative = {k: 0 for k in set(y_true)}\n",
    "    # Iterate over the true and predicted class labels\n",
    "    for i in range(len(y_true)):\n",
    "        # If the true and predicted class labels match\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            # Increment the count of true positive for that class label\n",
    "            if y_true[i] not in true_positive:\n",
    "                true_positive[y_true[i]] = 1\n",
    "            else:\n",
    "                true_positive[y_true[i]] += 1\n",
    "        # If the true and predicted class labels do not match\n",
    "        else:\n",
    "            # Increment the count of false negative for that class label\n",
    "            if y_true[i] not in false_negative:\n",
    "                false_negative[y_true[i]] = 1\n",
    "            else:\n",
    "                false_negative[y_true[i]] += 1\n",
    "    # Initialize an empty list to store recall for each class label\n",
    "    recall = []\n",
    "    # Calculate recall for each class label\n",
    "    for label in set(y_true):\n",
    "        recall.append(true_positive[label] / (true_positive[label] + false_negative[label]))\n",
    "    # Return the mean recall\n",
    "    return np.mean(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before normalization : \n",
      "Accuracy for k = 1: 0.9266666666666666\n",
      "Precision for k = 1: 0.9231903492391109\n",
      "Recall for k = 1: 0.9289286281851103 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 1: 0.8966666666666666\n",
      "Precision for k = 1: 0.8997205316613212\n",
      "Recall for k = 1: 0.8971835849801213 \n",
      "\n",
      "Before normalization : \n",
      "Accuracy for k = 3: 0.9533333333333334\n",
      "Precision for k = 3: 0.9530636688503068\n",
      "Recall for k = 3: 0.9535878167133005 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 3: 0.92\n",
      "Precision for k = 3: 0.9204365778345285\n",
      "Recall for k = 3: 0.9189922907115244 \n",
      "\n",
      "Before normalization : \n",
      "Accuracy for k = 5: 0.97\n",
      "Precision for k = 5: 0.9684366246498599\n",
      "Recall for k = 5: 0.9709004519946858 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 5: 0.9533333333333334\n",
      "Precision for k = 5: 0.9506444089324524\n",
      "Recall for k = 5: 0.9540849758042096 \n",
      "\n",
      "Before normalization : \n",
      "Accuracy for k = 7: 0.98\n",
      "Precision for k = 7: 0.9808358990147783\n",
      "Recall for k = 7: 0.9798942907582613 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 7: 0.95\n",
      "Precision for k = 7: 0.9470008302888737\n",
      "Recall for k = 7: 0.9512440667133004 \n",
      "\n",
      "Before normalization : \n",
      "Accuracy for k = 9: 0.9733333333333334\n",
      "Precision for k = 9: 0.9737937675070029\n",
      "Recall for k = 9: 0.974372674216908 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 9: 0.9533333333333334\n",
      "Precision for k = 9: 0.9493085225965661\n",
      "Recall for k = 9: 0.9540849758042096 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class KNeighborsClassifier:\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    def fit_with_norm(self, X_train, y_train):\n",
    "        self.X_train, self.X_test = normalize_dataframe(X_train, X_test)\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Initialize an empty list to store predictions\n",
    "        predictions = []\n",
    "        \n",
    "        # Iterate over each feature vector in X_test\n",
    "        for i in range(len(X_test)):\n",
    "            # Initialize an empty list to store distances\n",
    "            distances = []\n",
    "            \n",
    "            # Calculate the Euclidean distance between the current feature vector in X_test and all feature vectors in X_train\n",
    "            for j in range(len(self.X_train)):\n",
    "                dist = sum([(a-b)**2 for a,b in zip(X_test[i],self.X_train[j])])\n",
    "                distances.append([dist, j])\n",
    "            \n",
    "            # Sort the distances in ascending order and select the first 'n_neighbors' closest distances\n",
    "            distances = sorted(distances, key=lambda x: x[0])[:self.n_neighbors]\n",
    "            \n",
    "            # Initialize an empty list to store the class labels of the closest neighbors\n",
    "            neighbors = []\n",
    "            \n",
    "            # Add the class labels of the closest neighbors to the \"neighbors\" list\n",
    "            for k in range(self.n_neighbors):\n",
    "                index = distances[k][1]\n",
    "                neighbors.append(self.y_train[index])\n",
    "            \n",
    "            # Find the class label that appears most frequently in the \"neighbors\" list\n",
    "            # and append it to the \"predictions\" list as the prediction for the current feature vector\n",
    "            predictions.append(max(set(neighbors), key=neighbors.count))\n",
    "            \n",
    "        # Return the final list of predictions\n",
    "        return predictions\n",
    "\n",
    "\n",
    "# Define a list of possible values of k to try\n",
    "k_list = [1, 3, 5, 7, 9]\n",
    "\n",
    "# Use cross-validation to evaluate the performance of k-NN with different values of k\n",
    "cv_scores = []\n",
    "cv_scores_with_norm = []\n",
    "# Define the number of folds for cross-validation\n",
    "n_folds = 5\n",
    "\n",
    "for k_fold in k_list:\n",
    "    # Split the data into n_folds subsets\n",
    "    subsets = np.array_split(np.arange(len(independent_array)), n_folds)\n",
    "    k_scores = []\n",
    "    k_scores_with_norm = []\n",
    "    for i in range(n_folds):\n",
    "        # Use one subset for testing and the others for training\n",
    "        test_indices = subsets[i]\n",
    "        train_indices = np.concatenate(subsets[:i] + subsets[i+1:])\n",
    "        X_train, y_train = independent_array[train_indices], dependent_array[train_indices]\n",
    "        X_test, y_test = independent_array[test_indices], dependent_array[test_indices]\n",
    "\n",
    "\n",
    "    # Create a KNeighborsClassifier object with k_fold\n",
    "    knn = KNeighborsClassifier(n_neighbors=k_fold)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions_knn = knn.predict(X_test)\n",
    "    print(\"Before normalization : \")\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions_knn)\n",
    "    print(\"Accuracy for k = {}:\".format(k_fold), accuracy)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, predictions_knn)\n",
    "    print(\"Precision for k = {}:\".format(k_fold), precision)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = recall_score(y_test, predictions_knn)\n",
    "    print(\"Recall for k = {}:\".format(k_fold), recall,'\\n')\n",
    "    k_scores.append(accuracy)\n",
    "    cv_scores.append(np.mean(k_scores))\n",
    "\n",
    "    # with NORMALIZATION\n",
    "    print(\"After normalization : \")\n",
    "    knn.fit_with_norm(X_train, y_train)\n",
    "    X_test, _ = normalize_dataframe(X_test, X_train)\n",
    "    # Make predictions on the test set\n",
    "    predictions_knn_with_norm = knn.predict(X_test)\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions_knn_with_norm)\n",
    "    print(\"Accuracy for k = {}:\".format(k_fold), accuracy)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, predictions_knn_with_norm)\n",
    "    print(\"Precision for k = {}:\".format(k_fold), precision)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = recall_score(y_test, predictions_knn_with_norm)\n",
    "    print(\"Recall for k = {}:\".format(k_fold), recall,'\\n')\n",
    "    # evaluate predictions\n",
    "    score_with_normalization = accuracy_score(y_test, predictions_knn_with_norm)\n",
    "    k_scores_with_norm.append(score_with_normalization)\n",
    "    cv_scores_with_norm.append(sum(k_scores_with_norm)/len(k_scores_with_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Normalization : \n",
      "Accuracy for k = 1: 0.9266666666666666\n",
      "Precision for k = 1: 0.9231903492391109\n",
      "Recall for k = 1: 0.9289286281851103 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 1: 0.8966666666666666\n",
      "Precision for k = 1: 0.8997205316613212\n",
      "Recall for k = 1: 0.8971835849801213 \n",
      "\n",
      "Before Normalization : \n",
      "Accuracy for k = 3: 0.9533333333333334\n",
      "Precision for k = 3: 0.9489574579831932\n",
      "Recall for k = 3: 0.9535878167133005 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 3: 0.93\n",
      "Precision for k = 3: 0.9283037482669836\n",
      "Recall for k = 3: 0.9281543411975881 \n",
      "\n",
      "Before Normalization : \n",
      "Accuracy for k = 5: 0.9666666666666667\n",
      "Precision for k = 5: 0.9647825241207595\n",
      "Recall for k = 5: 0.9686683091375429 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 5: 0.95\n",
      "Precision for k = 5: 0.945032503476797\n",
      "Recall for k = 5: 0.9501480885493075 \n",
      "\n",
      "Before Normalization : \n",
      "Accuracy for k = 7: 0.9733333333333334\n",
      "Precision for k = 7: 0.9747916666666667\n",
      "Recall for k = 7: 0.974372674216908 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 7: 0.9566666666666667\n",
      "Precision for k = 7: 0.9525764964527752\n",
      "Recall for k = 7: 0.9579912258042096 \n",
      "\n",
      "Before Normalization : \n",
      "Accuracy for k = 9: 0.9733333333333334\n",
      "Precision for k = 9: 0.9738988095238096\n",
      "Recall for k = 9: 0.974372674216908 \n",
      "\n",
      "After normalization : \n",
      "Accuracy for k = 9: 0.9566666666666667\n",
      "Precision for k = 9: 0.9524335225965661\n",
      "Recall for k = 9: 0.9579912258042096 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "class WeightedKNeighborsClassifier:\n",
    "    def __init__(self, n_neighbors):\n",
    "        self.n_neighbors = n_neighbors\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "    def fit_with_norm(self, X_train, y_train):\n",
    "        self.X_train, self.X_test = normalize_dataframe(X_train, X_test)\n",
    "        self.y_train = y_train\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        # Initialize an empty list to store predictions\n",
    "        predictions = []\n",
    "\n",
    "        # Iterate over each feature vector in X_test\n",
    "        for i in range(len(X_test)):\n",
    "            # Initialize an empty list to store distances\n",
    "            distances = []\n",
    "\n",
    "            # Calculate the Euclidean distance between the current feature vector in X_test and all feature vectors in X_train\n",
    "            for j in range(len(self.X_train)):\n",
    "                dist = sum([(a-b)**2 for a,b in zip(X_test[i],self.X_train[j])])\n",
    "                distances.append([dist, j])\n",
    "\n",
    "            # Sort the distances in ascending order and select the first 'n_neighbors' closest distances\n",
    "            distances = sorted(distances, key=lambda x: x[0])[:self.n_neighbors]\n",
    "\n",
    "            # Initialize a dictionary to store the class labels of the closest neighbors with their corresponding weight\n",
    "            neighbors = {}\n",
    "\n",
    "            # Calculate the weight for each class label of the closest neighbors\n",
    "            for k in range(self.n_neighbors):\n",
    "                index = distances[k][1]\n",
    "                weight = 1 / (distances[k][0] + 0.00001) # weight = 1 / distance + epsilon to prevent division by zero\n",
    "                if self.y_train[index] in neighbors:\n",
    "                    neighbors[self.y_train[index]] += weight\n",
    "                else:\n",
    "                    neighbors[self.y_train[index]] = weight\n",
    "\n",
    "            # Find the class label with the highest weighted vote and append it to the \"predictions\" list as the prediction for the current feature vector\n",
    "            predictions.append(max(neighbors, key=neighbors.get))\n",
    "\n",
    "        # Return the final list of predictions\n",
    "        return predictions\n",
    "\n",
    "\n",
    "for k_fold in k_list:\n",
    "    # Split the data into n_folds subsets\n",
    "    subsets = np.array_split(np.arange(len(independent_array)), n_folds)\n",
    "    k_scores = []\n",
    "    for i in range(n_folds):\n",
    "        # Use one subset for testing and the others for training\n",
    "        test_indices = subsets[i]\n",
    "        train_indices = np.concatenate(subsets[:i] + subsets[i+1:])\n",
    "        X_train, y_train = independent_array[train_indices], dependent_array[train_indices]\n",
    "        X_test, y_test = independent_array[test_indices], dependent_array[test_indices]\n",
    "\n",
    "    # Create a KNeighborsClassifier object with k_fold\n",
    "    knn = WeightedKNeighborsClassifier(n_neighbors=k_fold)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    predictions_W_knn = knn.predict(X_test)\n",
    "    print(\"Before Normalization : \")\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions_W_knn)\n",
    "    print(\"Accuracy for k = {}:\".format(k_fold), accuracy)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, predictions_W_knn)\n",
    "    print(\"Precision for k = {}:\".format(k_fold), precision)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = recall_score(y_test, predictions_W_knn)\n",
    "    print(\"Recall for k = {}:\".format(k_fold), recall,\"\\n\")\n",
    "    k_scores.append(accuracy)\n",
    "    cv_scores.append(np.mean(k_scores))\n",
    "    \n",
    "    # with NORMALIZATION\n",
    "    print(\"After normalization : \")\n",
    "    knn.fit_with_norm(X_train, y_train)\n",
    "    X_test, _ = normalize_dataframe(X_test, X_train)\n",
    "    # Make predictions on the test set\n",
    "    predictions_knn_with_norm = knn.predict(X_test)\n",
    "\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions_knn_with_norm)\n",
    "    print(\"Accuracy for k = {}:\".format(k_fold), accuracy)\n",
    "\n",
    "    # Calculate precision\n",
    "    precision = precision_score(y_test, predictions_knn_with_norm)\n",
    "    print(\"Precision for k = {}:\".format(k_fold), precision)\n",
    "\n",
    "    # Calculate recall\n",
    "    recall = recall_score(y_test, predictions_knn_with_norm)\n",
    "    print(\"Recall for k = {}:\".format(k_fold), recall,'\\n')\n",
    "    # evaluate predictions\n",
    "    score_with_normalization = accuracy_score(y_test, predictions_knn_with_norm)\n",
    "    k_scores_with_norm.append(score_with_normalization)\n",
    "    cv_scores_with_norm.append(sum(k_scores_with_norm)/len(k_scores_with_norm))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis for Classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some misclassified data samples were found in the results predicted by the KNN algorithm.\n",
    "There are several reasons why a K-Nearest Neighbors (KNN) algorithm may misclassify some data:\n",
    "\n",
    "    1. The KNN algorithm is sensitive to the scale of the data. If the features in the dataset have different scales, the algorithm may misclassify some data points.\n",
    "\n",
    "    2. The choice of the value of K can also affect the performance of the algorithm. A small value of K can lead to overfitting, while a large value can lead to underfitting.\n",
    "\n",
    "    3. The presence of noisy or irrelevant features in the dataset can also affect the performance of the algorithm.\n",
    "\n",
    "    4. The algorithm can also be affected by the presence of outliers in the dataset.\n",
    "\n",
    "    5. If the data is not randomly sampled and is skewed in some way, this can lead to a bias in the model and misclassification.\n",
    "\n",
    "    6. If the training and test data is not independent and identically distributed, it can lead to poor generalization and misclassification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Effect of Neighbor Number (k) :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The Effect of Neighbor Number (k) in the K-Nearest Neighbors (KNN) algorithm refers to the number of nearest neighbors used to make a prediction. This parameter is used to control the complexity of the model and the amount of smoothing required to make predictions.\n",
    "\n",
    "    A small value of k, such as k=1, means that the algorithm will only consider the closest neighbor to make a prediction. This can lead to overfitting, as the model will be highly sensitive to noise in the training data.\n",
    "\n",
    "    A large value of k, such as k=100, means that the algorithm will consider a larger number of neighbors to make a prediction. This can lead to underfitting, as the model will be less sensitive to noise in the training data.\n",
    "\n",
    "    The optimal value of k will depend on the specific problem and the amount of noise in the data. A good starting point is to use a value of k that is the square root of the number of samples in the training set. However, this value should be adjusted as needed based on the results of cross-validation.\n",
    "\n",
    "    The choice of k also affects the decision boundary of the model. When k=1, the decision boundary is irregular and complex, while larger value of k leads to a smoother decision boundary with less complex shape.\n",
    "\n",
    "    It's worth noting that in case of a large k, the model becomes more robust to outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Effect of Normalization on the implementation of KNN algorithm :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Normalization, also known as feature scaling, is the process of transforming the features of a dataset to a common scale. This can be important in the implementation of the K-Nearest Neighbors (KNN) algorithm, as the algorithm is sensitive to the scale of the data.\n",
    "\n",
    "    When the features in a dataset have different scales, the algorithm may give more weight to features with larger scales and less weight to features with smaller scales. This can lead to the algorithm misclassifying some data points. By normalizing the features, the algorithm will give equal weight to all features, regardless of their scale.\n",
    "\n",
    "    There are several ways to normalize data, the most common being min-max normalization and standardization.\n",
    "\n",
    "    Min-max normalization scales the data to a specific range, usually between 0 and 1. The formula for min-max normalization is:\n",
    "\n",
    "    (x - xmin) / (xmax - xmin)\n",
    "\n",
    "    Where x is the original feature value, xmin is the minimum value of the feature in the dataset and xmax is the maximum value of the feature in the dataset.\n",
    "\n",
    "    Standardization scales the data to have a mean of 0 and a standard deviation of 1. The formula for standardization is:\n",
    "\n",
    "    (x - mean(x)) / std(x)\n",
    "\n",
    "    Where x is the original feature value, mean(x) is the mean of the feature in the dataset and std(x) is the standard deviation of the feature in the dataset.\n",
    "\n",
    "    By normalizing the data, the KNN algorithm will consider all the features on an equal footing, which can improve the accuracy of the model and reduce the chance of misclassification."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effect of K-fold :"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    K-fold cross-validation is a technique used to evaluate the performance of a machine learning model, including the K-Nearest Neighbors (KNN) algorithm. The process involves dividing the dataset into k subsets or \"folds\". The model is trained on k-1 of the folds and tested on the remaining fold. This process is repeated k times, with each fold being used as the test set once. The average performance of the model across all k iterations is used to estimate the model's performance on unseen data.\n",
    "\n",
    "    The main advantage of K-fold cross-validation is that it allows for the use of all the data for both training and testing, which can provide a more accurate estimate of the model's performance. Additionally, by repeating the process k times, it provides a more robust estimate of the model's performance by averaging out any variation that might occur due to the specific samples that are used for training and testing.\n",
    "\n",
    "    In the context of KNN algorithm, K-fold cross-validation can be used to tune the value of k, the number of nearest neighbors. By using a k-fold cross-validation, we can train the model on different subsets of the data and test it on different subsets as well. This allows us to evaluate the model's performance with different values of k and select the value that gives the best results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision and Recall"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Accuracy, precision, and recall are commonly used metrics to evaluate the performance of a machine learning model, including the K-Nearest Neighbors (KNN) algorithm.\n",
    "\n",
    "    Accuracy is the proportion of correctly classified instances over the total number of instances. It is calculated by dividing the number of correct predictions by the total number of predictions.\n",
    "\n",
    "    Precision is the proportion of true positive instances among all positive instances predicted by the model. It is calculated by dividing the number of true positive predictions by the number of true positive predictions plus the number of false positive predictions.\n",
    "\n",
    "    Recall is the proportion of true positive instances among all instances that are actually positive. It is calculated by dividing the number of true positive predictions by the number of true positive predictions plus the number of false negative predictions.\n",
    "\n",
    "    When evaluating the performance of a KNN model, it's important to consider the balance between precision and recall. High precision means that the model is not producing many false positives, while high recall means that the model is identifying most of the positive instances. Depending on the problem and the cost of false positives vs false negatives, a trade-off between precision and recall might be desired."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
